# Athlete Fatigue Analysis

## Motivation 

Fatigue and workload in an athlete’s season can be detrimental to the player and team performance. During a season of intense competition every weekend, there needs to be a balance of maintaining strength, endurance, and conditioning while not overloading the athlete with too much training. The goal is to have the athlete peak physically during game time by understanding their day-to-day training. Workload should be monitored as well for injury prevention to ensure each player is optimizing their time on the court or field. 

Being able to classify tennis players as fatigued, normal, or at their peak performance is crucial in determining the lineup, the duration of court time, and whether that individual is on the brink of a potentially season-ending injury. Being able to eliminate just one injury per team per year makes this machine learning model beneficial in saving the performance of a team for its season. 

## Data Overview 

The data we are using to demonstrate an understanding of CMJ data applications in athlete performance is from the University of Notre Dame’s Women’s Tennis team from the 2023 spring season. The team consists of ten female athletes who all compete at the collegiate Division 1 level. The ten athletes all completed 3 jumps a week during the 4 month season with 18 unique data points being gathered. For the purposes of this analysis we determined it would be best to narrow down from the ten athletes to three - two with clean data (Athlete 3 and 8) and one (Athlete 10) that was not.  Our definition of clean data for this analysis meant they had no outliers in jump height and eccentric peak power that could skew our model and performed the test every week during the season. Athlete 10 had outliers in both jump height and eccentric peak power. While outliers are generally not ideal, we wanted to show the reliability of our models and make sure this could be resistant to an abnormal jump. 

In the data gathered we determined that the most important variables to the initial part of our analysis were jump height, eccentric peak power, and the ratio of flight time to contraction time. We selected these variables because of their relationship to an athlete's fatigue and thus believe they will have a relationship with the players performance.

## Results 

Athlete 3 was the first clustering model we made, which was broken down into three clusters with sample sizes of 10, 11, and 12 respectively. When looking at the heat map of the clusters, cluster 1’s values all hover around 0 and with the strongest value being their asymmetry. Thus, we determined that this cluster represents their average performance level. Since cluster 2 contained primarily strongly positive values (with our important factors of jump height, eccentric peak power, and flight time to contraction time being some of those strong positive factors) it indicated that this cluster contains their top performances. Finally cluster 3 contains the athletes fatigued jumps based on the understanding that their values are primarily negative and close to -1. 

The clusters for Athlete 8 were more spread out than our previous cluster model created with each cluster having 9, 13, and 8, respectively. The heat map indicated that cluster 1 can be determined to be their fatigued jumps based on the values being predominantly negative. Clusters 2 and 3 are similar in their range of values, however cluster 2 was determined to be their better performance and cluster 3 their more average performance. This was based on the fact that cluster 2 has a positive flight to contraction time and eccentric peak power whereas cluster 3 has negative and 0 values for those important variables. 

Athlete 10’s number of samples for each cluster was a lot more spread out than the other having 16, 3, and 11. Even though the first cluster contains the most points that are slightly negative, they are relatively close to 0, so in this case represents this athlete's average performance. Whereas cluster 2’s values are highly negative indicating it is their fatigued jumps especially considering the scale for the values goes to negative 2 instead of just negative 1. However, is the cluster with only 3 samples, indicating that although they were way off, it was only a small proportion of their data. Finally, cluster 3 is the only cluster for this athlete with predominantly positive values meaning this cluster is the athlete's peak performance. 

Since the XGBoost model was going to be a regression, we decided to run a few multiple linear regression models first to see how well our variables might do at predicting the jump height. Our first model, just used flight_time_deviation and jump_height_deviation to predict next_weeks_jump_height and it performed very poorly with an adjusted r-squared value of 0.002863. The second model used the mean differences from the previous week (mean_diff_flight_time, mean_diff_jump_height, etc.) to predict next_weeks_jump_height and it also performed poorly with an adjusted r-squared value of 0.009084. Our third model used all of the variables except for the categorical variables to predict next_weeks_jump_height and it performed extremely well. It achieved an r-square value of 0.8977 with a p-value of less than 2.2e-16. Since this model performed the best, we knew to use all of the variables in our XGBoost Model. 

We ran XGBoost on our training data which used all of the variables except for the categorical variables and next_weeks_jump_height since it was the label. The booster was set to “gblinear” since we are running a regression. The number of rounds was set to 100 and the eval_metric was set to “rmse” or root-mean squared error. After running the model, the lowest training root-mean squared error was 0.6174327. We used the model to predict next_weeks_jump_height on the testing data and got an RMSE of 0.8056573 and an R-squared value of 0.7425691. The model actually performed better on the test set than the training set but it did not outperform the linear regression model. 


